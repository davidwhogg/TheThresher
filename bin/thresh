#!/usr/bin/env python
"""
This file is part of The Thresher.

This is the main user entry point for The Thresher (our lucky-imaging
replacement pipeline).

"""

import os
import sys
import glob
import logging
import datetime

import numpy as np
import pyfits

# This heinous hack let's me run this script without actually installing the
# `thresher` module. I learned this from Steve Losh at:
#     https://github.com/sjl/d/blob/master/bin/d
try:
    import thresher
    thresher = thresher  # Flake8... don't ask...
except ImportError:
    sys.path.append(os.path.abspath(os.path.join(__file__, '..', '..')))
    import thresher
    thresher = thresher

if __name__ == '__main__':
    import argparse

    # Start by parsing the command line arguments.
    desc = "Run online blind de-mixing on a lucky imaging data stream."
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument("-g", "--glob", type=str, default=None,
            help="The glob that the images must satisfy.")
    parser.add_argument("-o", "--output", type=str, default=None,
            help="The directory for the output files.")
    parser.add_argument("-i", "--initial_scene", type=str, nargs="*",
            default=None,
            help="A FITS file containing the initial scene with an optional "
                + "HDU number for the image and the metadata table.")
    parser.add_argument("-d", "--data_path", type=str, default=".",
            help="The basepath for the data files.")
    parser.add_argument("-m", "--no_median", action="store_true",
            help="Subtract the median of the scene?")
    parser.add_argument("--simple", action="store_true",
            help="Use stochastic gradient.")
    parser.add_argument("--use_non_neg", action="store_true",
            help="Use non-negativity?")
    parser.add_argument("--size", type=int, default=None,
            help="The size of the inferred scene.")
    parser.add_argument("--psf_hw", type=int, default=13,
            help="The half width of the inferred PSF image.")
    parser.add_argument("--psfreg", type=float, default=1.,
            help="The strength of the sum-to-one regularization on the PSF.")
    parser.add_argument("--sceneL2", type=float, default=0.0,
            help="The strength of the L2 regularization on the scene.")
    parser.add_argument("--sky", type=float, default=0.0,
            help="The sky level of the images")
    parser.add_argument("-n", "--npasses", type=int, default=1,
            help="The number of inference passes to run")
    parser.add_argument("-t", "--top", type=int, default=None,
            help="Only use the top N images as defined by the TLI ordering.")
    parser.add_argument("--log", type=str, default=None,
            help="The filename for the log.")
    parser.add_argument("-v", "--verbose", action="store_true",
            help="Enable verbose logging.")
    args = parser.parse_args()

    if args.output is None:
        outdir = os.path.join(os.getcwd(), "out")
    else:
        outdir = args.output

    try:
        os.makedirs(outdir)
    except os.error:
        pass

    # Set up the `logging` module with the settings provided at the command
    # line.
    loglevel = logging.INFO
    if args.verbose:
        loglevel = logging.DEBUG
    if args.log is None:
        logging.basicConfig(level=loglevel)
    else:
        logfn = os.path.join(outdir, args.log)
        logging.basicConfig(filename=logfn, level=loglevel, filemode="w")

    # If an initial scene is provided, try to load it and the metadata table.
    if args.initial_scene is not None:
        scene_fn = args.initial_scene[0]

        # Get the HDU numbers.
        try:
            scene_hdu = int(args.initial_scene[1])
        except IndexError:
            scene_hdu = 0
        try:
            table_hdu = int(args.initial_scene[2])
        except IndexError:
            table_hdu = scene_hdu + 1

        with pyfits.open(scene_fn) as hdus:
            initial_scene = np.array(hdus[scene_hdu].data, dtype=float)
            try:
                table = hdus[table_hdu].data
            except IndexError:
                table = None

        # Try to get the metadata.
        image_list, ranks, centers = None, None, None
        if table is not None:
            try:
                image_list = table["filename"]
                ranks = table["rank"]
                centers = np.vstack([table["x0"], table["y0"]]).T.astype(int)
            except KeyError:
                pass
        if image_list is None:
            logging.warn("There doesn't seem to be a metadata table in "
                    + "{0:s}. It was expected in HDU #{1:d}. "
                    .format(scene_fn, table_hdu))

            assert args.glob is not None, \
                    "You must provide a glob if the initial scene file " \
                    + "doesn't have metadata."
            image_list = glob.glob(args.glob)
        else:
            # Resolve the paths to the images.
            for i in range(len(image_list)):
                image_list[i] = os.path.join(args.data_path, image_list[i])
    else:
        logging.info("Running TLI to initialize the scene...")
        image_list, ranks, centers, initial_scene = \
                thresher.run_tli(glob.glob(args.glob), top_percent=1)
        initial_scene = initial_scene[1]

    # Trim the initial scene to be square with dimensions matching our
    # requests.
    if args.size is not None:
        size = args.size
    else:
        size = np.min(initial_scene.shape)
    initial_scene = thresher.utils.trim_image(initial_scene, size)
    initial_scene[np.isnan(initial_scene)] = np.median(initial_scene)

    # Write the command line arguments.
    f = open(os.path.join(outdir, "clargs"), "a")
    f.write("{0} - ".format(datetime.datetime.now()))
    f.write(" ".join(sys.argv))
    f.write("\n")
    f.close()

    # Start the inference.
    scene = thresher.Scene(initial_scene, image_list, outdir=outdir,
            centers=centers, psf_hw=args.psf_hw, psfreg=args.psfreg,
            sceneL2=args.sceneL2)

    # Thresh like mad.
    scene.run_inference(npasses=args.npasses, median=not args.no_median,
            nn=args.use_non_neg, top=args.top)
